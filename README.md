# MusicEmotion
The general idea of the project is to generate image from music. 

2022.07.11 try to evaluate the valence and arousal value for both songs and images


# Literature Review work trace. 

## A survey of music emotion recognition
Summarizing article: https://news.sciencenet.cn/htmlpaper/2022/6/20226231124191573739.shtm

## LyricJam: A system for generating lyrics for live instrumental music

receive live audio and generate lyrics

based on those artist that compose music before lyrics

two ways to generate lyrics

- based on adversarial alignment of latent representations of audio and lyrics
- transfer the **topology** from the music latent space to the lyric latent space



<u>mel-spectrograms</u>:

表示音阶是基于音高之间的比较

 the scale is based on the comparison between pitches.

The mel spectrogram remaps the values in hertz to the mel scale.

Mel scale梅尔音阶

是人类通常认为彼此等距的音高音阶

As frequency increases, the interval, in hertz, between mel scale values (or simply *mels*) increases.随着频率的增加，以赫兹为单位的 mel 标度值 之间的间隔增加

The name mel derives from *melody* and indicates that the scale is based on the comparison between pitches.



## The song is you

实验

<img src="/Users/jiangyijing/Desktop/y4-autumn/FYP/Reading/截屏2022-06-11 09.37.31.png" alt="截屏2022-06-11 09.37.31" style="zoom:50%;" />

##### study1

 Identify the <u>structure</u> underlying perceived attributes in music across a variety of genres

找arousal，valence，depth与不同类别音乐及其风格特点的关系

##### study2

音乐偏好和个人特征之间的相关性

##### conclusion

it may not be necessary for those who code and categorize music (in both industry and research) to code a plethora of attributes for each musical piece,



# The Do Re Mi’s of Everyday Life: The Structure and Personality Correlates of Music Preferences


## Color Music: Visual Color Notation for Musical Expression

discuss the relation between music and different colors

- SPACE, TEXTURE, TEMPO



## Deep Visual-Semantic Alignments for Generating Image Descriptions

align image with text 

- LSTM



## Text Summarization Techniques: A Brief Survey

**extractive summarization** techniques 

extract salient sentences using features like <u>word and phrase frequency</u>

sentence weight



 Two different approaches for **automatic summarization**: 

*<u>extraction</u>* 

produce summaries by choosing a subset of the sentences in the original text

1) Construct an intermediate representation of the in- put text which expresses the main aspects of the text.
2) Score the sentences based on the representation.
3) select a summary com- prising of a number of sentences.

 <u>*abstraction*</u>

produce important material in a new way



Purely extractive summaries often times give better results compared to automatic abstractive sum- maries 

## Framework for Abstractive Summarization using Text-to-Text Generation

##### New Concept

<u>information item (INIT)</u>

the smallest element of coherent informa- tion in a text or a sentence.

##### Step

- <u>INIT Retrieval</u>: use Semantic Role Labeling (SRL) and predicate- logic analysis of text to develop 
- <u>INIT selection</u>
- <u>Text generation</u>



## Segmentation Transformer: Object-Contextual Representations for Semantic Segmentation

图像处理

rephrase the <u>object-contextual</u> representation scheme using the Transformer encoder-decoder framework

Pixel: the label of a pixel is the category of the object that the pixel belongs to

Step1 object region

Step2 region representation computation

Integrate 1 & 2 using cross attention module in decoder (the linear projec- tions used to classify the pixels)



## Split and Rephrase: Better Evaluation and a Stronger Baseline

transforming complex sentence into several sentences

**BLEU**(Bilingual Evaluation Understudy)

https://www.aclweb.org/anthology/P02-1040

<img src="/Users/jiangyijing/Desktop/y4-autumn/FYP/Reading/截屏2022-06-17 13.44.27.png" alt="截屏2022-06-17 13.44.27" style="zoom:50%;" />

used for evaluating the text generated by machine (higher -- better performance)

## Mimic and Rephrase: Reflective listening in open-ended dialogue



## Bridging Music and Image via Cross-Modal Ranking Analysis

how music and image can be automatically matched by machines. 

propose cross-modal ranking analysis (CMRA) to learn the <u>semantic similarity</u> between music and image with ranking labeling information.

<u>Stanford Parser</u> [53] is utilized to extract adjectives, nouns, and phrases from all the lyric sentences, and four labelers are then asked to refine these phrases

Canonical Correlation Analysis典型相关分析

https://baike.baidu.com/item/典型相关分析/9298162

## EMOTIONAL VALENCE CATEGORIZATION USING HOLISTIC IMAGE FEATURES

<u>**Wiccest features**</u> utilize natural image statistics to effectively model texture information.

**<u>Gabor filters</u>** may be used to measure perceptual surface texture in an imag







## Predicting Continuous Probability Distribution of Image Emotions in Valence-Arousal Space

predict the continuous probability distribution of image emotions represented in VA space, which can be viewed as an initial attempt to measure the subjective evaluation of human perceptions. 

We formulize the emotion distribution prediction as a multi-task shared sparse regression (MTSSR) problem, which is optimized by iteratively reweighted least squares. Experiments are conducted on the Image- Emotion-Social-Net dataset to demonstrate the effectiveness of the proposed emotion distribution prediction method.



## Survey: Mood Detection in Images

According to Gonzalez and Woods " An image may be defined as a <u>two-dimensional function</u>, f ( x, y), where x and y are spatial coordinates, and the amplitude of f at any pair of coordinates ( x, y ) is called the <u>intensity or gray level</u> of the image at that point. When x, y, and the amplitude values of f are all finite, discrete quantities, we call the image a digital image."

- color
- texture
- shape

Map to high level semantics



## Joint Image Emotion Classification and Distribution Learning via Deep Convolutional Neural Network
Develop a deep multi-task framework to address the problem(difficult to learn robust emotional representations for predicting the image la- bels) 
The softmax is employed as the classification constraints, and the Kullback-Leibler (KL) loss is added for distribution learning. 




## International Affective Picture System (IAPS): Technical Manual and Affective Ratings

assess the three dimensions of pleasure, arousal, and dominance, the Self-Assessment Manikin (SAM), an affective rating system devised by Lang (1980) was used.



## OUTLINE OF MUSIC SEMANTICS

the meaning of a musical piece is given by the inferences that one can draw about its ‘‘virtual sources

1. First, we take properties of normal (non-musical) auditory cognition to make it possible to identify one or several ‘‘virtual’’ sources of the music
2. Second, we take further inferences about these sources to be drawn from their behavior within tonal pitch space



## LEARNING AFFECTIVE CORRESPONDENCE BETWEEN MUSIC AND IMAGE

build a model that can identify whether or not a music-image pair contains similar informa- tion in terms of emotion

## Multi-scale Context Based Attention for Dynamic Music Emotion Prediction
LTSM 
基于多尺度上下文的注意（MCA）用于动态音乐情感预测
配价中的表现提升不如说是唤醒中的表现提升。这可能是因为以下原因：首先，配价实际上比唤醒更难预测，这可以通过所有配价结果都比唤醒结果更糟糕的事实来发现。第二，测试集的配价注释与唤醒注释之间的一致性较差，这可能会在一定程度上影响最终结果。
与最先进的模型相比，除了基于DBLSTM的多尺度融合模型外，MCA模型的性能超过了所有单一模型，该模型利用了多个模型中包含的信息，并将它们混合以获得更好的性能 
不同时间尺度的前期内容会对LSTM模型产生影响

## Introducing the Open Affective Standardized Image Set (OASIS)
###dataset
valence and arousal ratings displayed to one or more image categories
www.benedekkurdi.com/#oasis
